{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/jonathan/2024_czii_mlchallenge_notebooks/pyUNET/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import zarr, copick\n",
    "from tqdm import tqdm\n",
    "from monai.data import DataLoader, CacheDataset, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    EnsureChannelFirstd, \n",
    "    ScaleIntensityRanged, \n",
    "    CropForegroundd, \n",
    "    Orientationd, \n",
    "    Spacingd, \n",
    "    EnsureTyped, \n",
    "    Activations, \n",
    "    AsDiscrete, \n",
    "    Resized, \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    RandZoomd,\n",
    "    RandGridPatchd,\n",
    "    NormalizeIntensityd,\n",
    "    RandCropByLabelClassesd,\n",
    "    Resized, \n",
    "    RandZoomd,\n",
    "    Activations, \n",
    "    CropForegroundd, \n",
    "    ScaleIntensityRanged, \n",
    "    RandCropByPosNegLabeld,    \n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss, FocalLoss, TverskyLoss\n",
    "from monai.metrics import DiceMetric, ConfusionMatrixMetric\n",
    "# from skimage\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from monai.transforms import Compose, EnsureChannelFirstd, NormalizeIntensityd, Orientationd, RandCropByLabelClassesd, RandRotate90d, RandFlipd\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "import mlflow, optuna, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "copick_config_path = \"../../../simulations/ml_challenge/ml_config.json\"\n",
    "root = copick.from_file(copick_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tomogram_array(copick_run, voxel_spacing=10, tomo_type='wbp'):\n",
    "    voxel_spacing_obj = copick_run.get_voxel_spacing(voxel_spacing)\n",
    "    tomogram = voxel_spacing_obj.get_tomogram(tomo_type)\n",
    "    image = zarr.open(tomogram.zarr(), mode='r')['0']\n",
    "    return image[:]\n",
    "\n",
    "def get_segmentation_array(copick_run, segmentation_name, voxel_spacing=10, is_multilabel=True):\n",
    "    #seg_memb = copick_run.get_segmentations(name=\"membrane\")\n",
    "    seg_memb = copick_run.get_segmentations()\n",
    "    seg = copick_run.get_segmentations(is_multilabel=is_multilabel, name=segmentation_name, voxel_size=voxel_spacing)\n",
    "    if len(seg) == 0:\n",
    "        raise ValueError(f\"No segmentations found for session '{session_id}' and segmentation type '{segmentation_type}'.\")\n",
    "        \n",
    "    segmentation = zarr.open(seg[0].zarr().path, mode=\"r\")['0'][:]\n",
    "    _, array = list(zarr.open(seg_memb[0].zarr()).arrays())[0]\n",
    "    seg_membrane = np.array(array[:])\n",
    "    #seg_membrane = zarr.open(seg_memb[0].zarr().path, mode=\"r\")['0'][:]\n",
    "    segmentation[seg_membrane==1] = 1\n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "voxel_spacing = 10\n",
    "tomo_type = \"wbp\"\n",
    "painting_segmentation_name = \"segmentation\" #\"remotetargets\"\n",
    "\n",
    "runIDs = [run.name for run in root.runs]\n",
    "data_dicts = []\n",
    "for runID in tqdm(runIDs):\n",
    "    run = root.get_run(str(runID))\n",
    "    tomogram = get_tomogram_array(run)\n",
    "    segmentation = get_segmentation_array(run, painting_segmentation_name)\n",
    "    data_dicts.append({\"image\": tomogram, \"label\": segmentation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 15\n",
      "Number of validation samples: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 15/15 [00:00<00:00, 24.33it/s]\n",
      "Loading dataset: 100%|██████████| 7/7 [00:00<00:00, 25.15it/s]\n"
     ]
    }
   ],
   "source": [
    "my_num_samples = 16\n",
    "train_batch_size = 1\n",
    "val_batch_size = 1\n",
    "\n",
    "test_files = data_dicts[-2:]\n",
    "train_files, val_files = train_test_split(data_dicts[:-2], test_size=0.3)\n",
    "print(f\"Number of training samples: {len(train_files)}\")\n",
    "print(f\"Number of validation samples: {len(val_files)}\")\n",
    "\n",
    "# Non-random transforms to be cached\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")\n",
    "])\n",
    "\n",
    "# Random transforms to be applied during training\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[96, 96, 96],\n",
    "        num_classes=8,\n",
    "        num_samples=my_num_samples\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),    \n",
    "])\n",
    "\n",
    "# Create the cached dataset with non-random transforms\n",
    "train_ds = CacheDataset(data=train_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "# Wrap the cached dataset to apply random transforms during iteration\n",
    "train_ds = Dataset(data=train_ds, transform=random_transforms)\n",
    "\n",
    "# DataLoader remains the same\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Validation transforms\n",
    "val_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[96, 96, 96],\n",
    "        num_classes=8,\n",
    "        num_samples=my_num_samples,  # Use 1 to get a single, consistent crop per image\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Create validation dataset\n",
    "val_ds = CacheDataset(data=val_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "# Wrap the cached dataset to apply random transforms during iteration\n",
    "val_ds = Dataset(data=val_ds, transform=random_transforms)\n",
    "\n",
    "# Create validation DataLoader\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=val_batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    shuffle=False,  # Ensure the data order remains consistent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = DiceLoss(include_background=True, to_onehot_y=True, softmax=True)  # softmax=True for multiclass\n",
    "loss_function = TverskyLoss(include_background=True, to_onehot_y=True, softmax=True)  \n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", ignore_empty=True)  # must use onehot for multiclass\n",
    "recall_metric = ConfusionMatrixMetric(include_background=False, metric_name=\"recall\", reduction=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_patches(data):\n",
    "    shape = data.shape\n",
    "    new_shape = (shape[0] * shape[1],) + shape[2:]\n",
    "    return data.view(new_shape)\n",
    "\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=len(root.pickable_objects)+1)\n",
    "post_label = AsDiscrete(to_onehot=len(root.pickable_objects)+1)\n",
    "\n",
    "def train(train_loader, \n",
    "          val_loader, \n",
    "          model, \n",
    "          device,\n",
    "          loss_function, \n",
    "          metrics_function, \n",
    "          optimizer, \n",
    "          max_epochs=100,\n",
    "          val_interval = 10,\n",
    "          verbose=True):\n",
    "    \n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs = batch_data[\"image\"].to(device)  # Shape: [B, C, H, W, D]\n",
    "            labels = batch_data[\"label\"].to(device)  # Shape: [B, C, H, W, D]            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)    # Output shape: [B, num_classes, H, W, D]\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(f\"batch {step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch+1)\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_inputs = val_data[\"image\"].to(device)\n",
    "                    val_labels = val_data[\"label\"].to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    \n",
    "                    # Decollate batches into lists\n",
    "                    val_outputs_list = decollate_batch(val_outputs)\n",
    "                    val_labels_list = decollate_batch(val_labels)\n",
    "                    # Apply post-processing\n",
    "                    metric_val_outputs = [post_pred(i) for i in val_outputs_list]\n",
    "                    metric_val_labels = [post_label(i) for i in val_labels_list]\n",
    "                    # Compute metrics\n",
    "                    metrics_function(y_pred=metric_val_outputs, y=metric_val_labels)\n",
    "\n",
    "                metrics = metrics_function.aggregate(reduction=\"mean_batch\")\n",
    "                metric_per_class = [\"{:.4g}\".format(x) for x in metrics]\n",
    "                metric = torch.mean(metrics).numpy(force=True)\n",
    "                mlflow.log_metric(\"validation metric\", metric, step=epoch+1)\n",
    "                for i,m in enumerate(metrics):\n",
    "                    mlflow.log_metric(f\"validation metric class {i+1}\", m, step=epoch+1)\n",
    "                metrics_function.reset()\n",
    "\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join('./', \"best_metric_model.pth\"))\n",
    "                    \n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean recall per class: {', '.join(metric_per_class)}\"\n",
    "                    f\"\\nbest mean recall: {best_metric:.4f} \"\n",
    "                    f\"at epoch: {best_metric_epoch}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set the seed for Python's random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set the seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set the seed for PyTorch (both CPU and GPU)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # If using multi-GPU\n",
    "\n",
    "    # Ensure reproducibility of operations by disabling certain optimizations\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,  \n",
    "              n_classes,\n",
    "              train_loader, \n",
    "              val_loader, \n",
    "              loss_function,\n",
    "              metrics_function, \n",
    "              epochs,\n",
    "              random_seed = 42,\n",
    "              gpu_count = 1):\n",
    "\n",
    "    set_seed(random_seed)\n",
    "\n",
    "    # Assign each trial to a specific GPU based on the trial number\n",
    "    if gpu_count > 1:\n",
    "        gpu_id = trial.number % gpu_count  # Cycle through available GPUs\n",
    "        device = torch.device(f\"cuda:{gpu_id}\")\n",
    "        torch.cuda.set_device(device)  # Set the current GPU for this trial\n",
    "    else:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    # Set a unique run name for each trial\n",
    "    trial_num = f\"trial_{trial.number}\"\n",
    "\n",
    "    # Start a new MLflow run for each trial\n",
    "    with mlflow.start_run(run_name = trial_num, nested=True):  # Nested=True allows it to be part of the overall experiment run\n",
    "        \n",
    "        # Sample number of channels\n",
    "        num_layers = trial.suggest_int(\"num_layers\", 2, 5)\n",
    "        \n",
    "        # Generate increasing channels based on 16, 32, 64\n",
    "        base_channel = trial.suggest_categorical(\"base_channel\", [8, 16, 32, 64])\n",
    "        channels = [base_channel * (2 ** i) for i in range(num_layers)]\n",
    "\n",
    "        # Strides pattern\n",
    "        # Sample number of downsampling layers (those with stride of 2)\n",
    "        num_downsampling_layers = trial.suggest_int(\"num_downsampling_layers\", 1, num_layers - 1)\n",
    "\n",
    "        # Define strides: first num_downsampling_layers with stride 2, and the rest with stride 1\n",
    "        strides_pattern = [2] * num_downsampling_layers + [1] * (num_layers - num_downsampling_layers)        \n",
    "\n",
    "        # Number of residual units\n",
    "        num_res_units = trial.suggest_int(\"num_res_units\", 1, 3)\n",
    "\n",
    "        print('Current Parameters: ')\n",
    "        print(f'Num Layers: {num_layers}')\n",
    "        print(f'Num Res Units: {num_res_units}')\n",
    "        print(f'Channels: {channels}')\n",
    "        print(f'Num Downsampling Layers: {num_downsampling_layers}')\n",
    "        print(f'Strides: {strides_pattern}\\n')\n",
    "\n",
    "        # Log parameters to MLflow at each trial\n",
    "        mlflow.log_params({\n",
    "            \"num_layers\": num_layers,\n",
    "            \"base_channel\": base_channel,\n",
    "            \"channels\": channels,\n",
    "            \"num_downsampling_layers\": num_downsampling_layers,\n",
    "            \"strides_pattern\": strides_pattern,\n",
    "            \"num_res_units\": num_res_units,\n",
    "            \"random_seed\": random_seed\n",
    "        })\n",
    "\n",
    "        # Now use channels, strides, and num_res_units in your model definition\n",
    "        model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=n_classes,\n",
    "            channels=channels,\n",
    "            strides=strides_pattern,\n",
    "            num_res_units=num_res_units,\n",
    "        ).to(device)\n",
    "\n",
    "        # # Sample learning rate using Optuna\n",
    "        # learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
    "\n",
    "        # Define your loss and optimizer, and return the objective (e.g., validation loss)\n",
    "        lr = 1e-3\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "        # score = train(train_loader, val_loader, \n",
    "        #               model, device, loss_function, \n",
    "        #               metrics_function, \n",
    "        #               optimizer, max_epochs=epochs)\n",
    "        \n",
    "        score = 1\n",
    "\n",
    "        # Log the score (e.g., validation loss or F1 score) for each trial\n",
    "        mlflow.log_metric(\"score\", score)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-GPU Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 01:30:08,722] A new study created in memory with name: no-name-937eb630-ceea-41fc-8612-8406d9274cf2\n",
      "/mnt/jonathan/2024_czii_mlchallenge_notebooks/pyUNET/lib/python3.10/site-packages/monai/networks/nets/unet.py:130: UserWarning: `len(strides) > len(channels) - 1`, the last 1 values of strides will not be used.\n",
      "  warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n",
      "[I 2024-10-17 01:30:08,832] Trial 0 finished with value: 1.0 and parameters: {'num_layers': 2, 'base_channel': 32, 'num_downsampling_layers': 1, 'num_res_units': 1}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Architecture Search Over 1 GPUS\n",
      "\n",
      "Current Parameters: \n",
      "Num Layers: 2\n",
      "Num Res Units: 1\n",
      "Channels: [32, 64]\n",
      "Num Downsampling Layers: 1\n",
      "Strides: [2, 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 01:30:08,971] Trial 1 finished with value: 1.0 and parameters: {'num_layers': 3, 'base_channel': 64, 'num_downsampling_layers': 2, 'num_res_units': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-10-17 01:30:09,071] Trial 2 finished with value: 1.0 and parameters: {'num_layers': 2, 'base_channel': 64, 'num_downsampling_layers': 1, 'num_res_units': 1}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters: \n",
      "Num Layers: 3\n",
      "Num Res Units: 3\n",
      "Channels: [64, 128, 256]\n",
      "Num Downsampling Layers: 2\n",
      "Strides: [2, 2, 1]\n",
      "\n",
      "Current Parameters: \n",
      "Num Layers: 2\n",
      "Num Res Units: 1\n",
      "Channels: [64, 128]\n",
      "Num Downsampling Layers: 1\n",
      "Strides: [2, 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 01:30:09,174] Trial 3 finished with value: 1.0 and parameters: {'num_layers': 2, 'base_channel': 64, 'num_downsampling_layers': 1, 'num_res_units': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-10-17 01:30:09,277] Trial 4 finished with value: 1.0 and parameters: {'num_layers': 3, 'base_channel': 8, 'num_downsampling_layers': 2, 'num_res_units': 1}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters: \n",
      "Num Layers: 2\n",
      "Num Res Units: 1\n",
      "Channels: [64, 128]\n",
      "Num Downsampling Layers: 1\n",
      "Strides: [2, 1]\n",
      "\n",
      "Current Parameters: \n",
      "Num Layers: 3\n",
      "Num Res Units: 1\n",
      "Channels: [8, 16, 32]\n",
      "Num Downsampling Layers: 2\n",
      "Strides: [2, 2, 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 01:30:09,468] Trial 5 finished with value: 1.0 and parameters: {'num_layers': 4, 'base_channel': 64, 'num_downsampling_layers': 2, 'num_res_units': 2}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters: \n",
      "Num Layers: 4\n",
      "Num Res Units: 2\n",
      "Channels: [64, 128, 256, 512]\n",
      "Num Downsampling Layers: 2\n",
      "Strides: [2, 2, 1, 1]\n",
      "\n",
      "Current Parameters: \n",
      "Num Layers: 3\n",
      "Num Res Units: 2\n",
      "Channels: [8, 16, 32]\n",
      "Num Downsampling Layers: 1\n",
      "Strides: [2, 1, 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 01:30:09,580] Trial 6 finished with value: 1.0 and parameters: {'num_layers': 3, 'base_channel': 8, 'num_downsampling_layers': 1, 'num_res_units': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-10-17 01:30:09,763] Trial 7 finished with value: 1.0 and parameters: {'num_layers': 5, 'base_channel': 16, 'num_downsampling_layers': 4, 'num_res_units': 2}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters: \n",
      "Num Layers: 5\n",
      "Num Res Units: 2\n",
      "Channels: [16, 32, 64, 128, 256]\n",
      "Num Downsampling Layers: 4\n",
      "Strides: [2, 2, 2, 2, 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 01:30:09,906] Trial 8 finished with value: 1.0 and parameters: {'num_layers': 2, 'base_channel': 8, 'num_downsampling_layers': 1, 'num_res_units': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-10-17 01:30:10,009] Trial 9 finished with value: 1.0 and parameters: {'num_layers': 2, 'base_channel': 8, 'num_downsampling_layers': 1, 'num_res_units': 1}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters: \n",
      "Num Layers: 2\n",
      "Num Res Units: 3\n",
      "Channels: [8, 16]\n",
      "Num Downsampling Layers: 1\n",
      "Strides: [2, 1]\n",
      "\n",
      "Current Parameters: \n",
      "Num Layers: 2\n",
      "Num Res Units: 1\n",
      "Channels: [8, 16]\n",
      "Num Downsampling Layers: 1\n",
      "Strides: [2, 1]\n",
      "\n",
      "Best trial: 1.0\n",
      "Best params: {'num_layers': 2, 'base_channel': 32, 'num_downsampling_layers': 1, 'num_res_units': 1}\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "num_trials = 10\n",
    "nclasses = len(root.pickable_objects)+1\n",
    "loss_function = TverskyLoss(include_background=True, to_onehot_y=True, softmax=True)  \n",
    "my_metrics = ConfusionMatrixMetric(include_background=False, metric_name=[\"recall\",'precision','f1 score'], reduction=\"None\")\n",
    "\n",
    "# Get available GPUs (for example, on an 8 GPU node)\n",
    "gpu_count = torch.cuda.device_count()\n",
    "\n",
    "print(f'Running Architecture Search Over {gpu_count} GPUS\\n')\n",
    "mlflow.set_experiment('unet-model-search')\n",
    "with mlflow.start_run():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, nclasses, train_loader, val_loader, loss_function, my_metrics, epochs), \n",
    "                   n_trials=num_trials,\n",
    "                   n_jobs=gpu_count) # Run trials on multiple GPUs\n",
    "\n",
    "    print(f\"Best trial: {study.best_trial.value}\")\n",
    "    print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "    # # Log the best trial in MLflow\n",
    "    # mlflow.log_metric(\"best_trial_value\", study.best_trial.value)\n",
    "    # mlflow.log_params(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "num_trials = 10\n",
    "nclasses = len(root.pickable_objects)+1\n",
    "loss_function = TverskyLoss(include_background=True, to_onehot_y=True, softmax=True)  \n",
    "my_metrics = ConfusionMatrixMetric(include_background=False, metric_name=[\"recall\",'precision','f1 score'], reduction=\"None\")\n",
    "\n",
    "# Get available GPUs (for example, on an 8 GPU node)\n",
    "my_gpu_count = torch.cuda.device_count()\n",
    "\n",
    "mlflow.set_experiment('unet-model-search')\n",
    "with mlflow.start_run():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, nclasses, train_loader, val_loader, loss_function, my_metrics, epochs, gpu_count = my_gpu_count), \n",
    "                   n_trials=num_trials,\n",
    "                   n_jobs=my_gpu_count) # Run trials on multiple GPUs\n",
    "\n",
    "    print(f\"Best trial: {study.best_trial.value}\")\n",
    "    print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "    # # Log the best trial in MLflow\n",
    "    # mlflow.log_metric(\"best_trial_value\", study.best_trial.value)\n",
    "    # mlflow.log_params(study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
